---
title: "Fitness Data Analysis"
author: "BI"
date: "December 18, 2015"
output: html_document
---

The purpose of this analysis is to look at fitness data collected on personal fitness monitors in 5 minute increments. The data set analyzed is the Activity Monitoring Data in the csv file activity.csv.

We begin our analysis by loading the dataset and R packages we will be needing for the analysis.

```{r}
library(ggplot2)
library(dplyr)
library(xtable)
library(lattice)
library(plotly)
Data <- read.csv("activity.csv", header = TRUE)
```

Next I use the aggregate function to calculate the number of steps by date and then create a histogram of the result.

```{r}
spds <- aggregate(steps~date, data=Data, sum)
hist(spds$steps, ylab = "Number of Days", xlab = "Sum of Steps", main = "Steps per Day")
```

Next I look at the mean data on a daily basis and I get the following:

```{r}
aggregate(steps~date, data=Data, mean)
```

When we print out the median we the result is so small that we get a lot of 0s as a result. Here are a few rows to demonstrate.

```{r}
demo <- aggregate(steps~date, data=Data, median)
demo[1:5, ]
```

Looking at the data set it is easy to see why. The data is overwhelmed by the number of zeros.Of 17,568 observations 11,014 are 0

```{r}
sum(Data$steps == 0, na.rm = TRUE)
```

I chose to groom the data to give a more meaningful result. I subsetted for the data for values that were not NA or 0 and calculated the median on the result. This is not a daily median, but a media for the entire data set less zeros and NAs. I then calculate the median of the average daily number of steps.

```{r}
mdsna <- Data[,1]
mdsna <- mdsna[!is.na(mdsna)]
mdsna <- mdsna[mdsna != 0]
md <- median(mdsna)
md
mdd <- aggregate(steps~date, data=Data, mean)
median(mdd$steps)
```

I use the aggregate function to create a new data set of mean steps and by interval and plot the result and return the maximum value by interval
```{r}
spd <- aggregate(steps~interval, data=Data, mean)
plot(spd$interval, spd$steps, type = "l", xlab = "5 Minute Intervals", ylab = "Average Number of Steps")
spdmx <- spd[order(-spd$steps),]
spdmx[1,]
```

There are a lot of missing data points in the original set. We can insert the mean in the place of the missing values. This will center the data more around the mean. First a count of the number of missing data points or NAs. To start with lets look at each column seperately.

```{r}
sum(is.na(Data$steps))
sum(is.na(Data$date))
sum(is.na(Data$interval))
```

The only column with NAs is the steps column which contains 2,304 missing data points. We can replace the NAs with the median value for the daily average calculated above.

```{r}
mn <- median(mdd$steps)
Dataadj <- Data
Dataadj[is.na(Dataadj)] <- mn
```

I now create a histogram of the results. Not surprisingly the histogram follows the same general shape as the original but with a higher peak as the data clusters more tightly around the mean. 

```{r}
spdadj <- aggregate(steps~date, data=Dataadj, sum)
hist(spdadj$steps, ylab = "Number of Days", xlab = "Sum of Steps", main = "Adjusted Steps per Day")
```

Next we look at the mean and median of the adjusted data set. As expected, the values are more closely clustered around the mean. We get some values for the median in this set but these values are heavily influence by the adjusted data.

```{r}
aggregate(steps~date, data=Dataadj, mean)
aggregate(steps~date, data=Dataadj, median)
```

```{r}
Datadys <- mutate(Data, wkdy = weekdays(as.POSIXlt(Data$date)))
Datawe <- filter(Datadys, wkdy == c("Saturday", "Sunday"))
Dagwe <- aggregate(steps~date, data=Datawe, sum)
Datawd <- filter(Datadys, wkdy == c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"))
Dagwd <- aggregate(steps~date, data=Datawd, sum)

par(mfrow = c(1,2))
plot_ly(data = Dagwe, x = date, y = steps)
plot_ly(data = Dagwd, x = date, y = steps)
```

